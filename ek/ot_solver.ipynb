{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train = np.load('../datasets/ratings_train.npy')\n",
    "ratings_test = np.load('../datasets/ratings_test.npy')\n",
    "m,n = ratings_train.shape\n",
    "data = np.nan_to_num(ratings_train)\n",
    "\n",
    "movies_average_rating = np.nanmean(ratings_train, axis=0)\n",
    "users_average_rating = np.nanmean(ratings_train, axis=1)\n",
    "movies_average_rating_normalized = movies_average_rating / movies_average_rating.sum()\n",
    "users_average_rating_normalized = users_average_rating / users_average_rating.sum()\n",
    "\n",
    "movies_total_rating = np.nansum(ratings_train, axis=0)\n",
    "users_total_rating = np.nansum(ratings_train, axis=1)\n",
    "users_normalized_total_rating = users_total_rating / users_total_rating.sum()\n",
    "movies_normalized_total_rating = movies_total_rating / movies_total_rating.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(c,l):\n",
    "    return l*np.power(np.linalg.norm(c),2)/2\n",
    "\n",
    "def gradient_ridge_reg(c,c_hat,gamma,l):\n",
    "    return l*c + (c - c_hat)/gamma\n",
    "\n",
    "\n",
    "\n",
    "def compute_prox(c_hat, h_prox, x0, iterations = 100, gamma = 0.01, epsilon = 0.001,l = 0.01): #h is the non-differentiable function\n",
    "    xk = x0\n",
    "    gk = np.power(np.linalg.norm(xk-c_hat),2)/(2*gamma)\n",
    "    for i in range(iterations):\n",
    "        xk_old = xk\n",
    "        # compute gradient for differentiable  part of function\n",
    "        gk_gradient = gradient_ridge_reg(xk,c_hat,gamma,l)\n",
    "        # take gradient step to reduce g(x)\n",
    "        xk_gradient = xk - gamma * gk_gradient\n",
    "        # proximal update to reduce h(x) but stay close to xk_gradient\n",
    "        xk = xk_gradient #Change if h is constraining function\n",
    "\n",
    "        if np.linalg.norm(xk - xk_old) < epsilon:\n",
    "            print(f'we are here buddd in {i}')\n",
    "            return xk\n",
    "\n",
    "    return xk\n",
    "\n",
    "def current_h(x,gamma):\n",
    "    return 0\n",
    "\n",
    "\n",
    "def cost_learning(data, pi_hat,mu,nu,epsilon,G, D, steps = 100):\n",
    "    m,n = pi_hat.shape\n",
    "    alpha = np.random.rand(m,1)\n",
    "    beta = np.random.rand(n,1)\n",
    "    u = np.exp(alpha / epsilon)\n",
    "    v = np.exp(beta / epsilon)\n",
    "    c = data\n",
    "    \n",
    "    G_inv = np.linalg.pinv(G)\n",
    "    D_inv = np.linalg.pinv(D)\n",
    "\n",
    "    A = np.random.rand(G_inv.shape[1], D_inv.shape[1])\n",
    "    \n",
    "    c_s = []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        K = np.exp(-c/epsilon)\n",
    "        kv = np.dot(K,v).reshape(m,1)\n",
    "        u = np.divide(mu.reshape(1,m),kv.reshape(1,m)).reshape(m,1)\n",
    "        ktu = np.dot(K.T,u).reshape(n,1)\n",
    "        v = np.divide(nu.reshape(1,n),ktu.reshape(1,n)).reshape(n,1)\n",
    "        K = pi_hat / (np.dot(u,v.T))\n",
    "        log_k = np.log(K, out=np.zeros_like(K), where=(K!=0))\n",
    "        A_deomposed = G_inv.T@log_k@D_inv\n",
    "        A = compute_prox(-epsilon*A_deomposed,current_h,A)\n",
    "        c = G.T@A@D\n",
    "        c = np.log(1 + np.exp(c))\n",
    "        #c_s.append(c)\n",
    "        #c = compute_prox(-epsilon*log_k,current_h,c)\n",
    "        if np.linalg.norm(c - c_s[-1]) < epsilon:\n",
    "            print(f'Cs equivalent in iteration {i}')\n",
    "\n",
    "\n",
    "    return epsilon*np.log(u),epsilon*np.log(v),c\n",
    "\n",
    "\n",
    "def transform_to_integers(matrix):\n",
    "    num_intervals = 10\n",
    "    min_value = matrix.min()\n",
    "    max_value = matrix.max()\n",
    "\n",
    "    # Calculate the interval width\n",
    "    interval_width = (max_value - min_value) / num_intervals\n",
    "\n",
    "    # Map the values to integers between 1 and 10\n",
    "    transformed_matrix = ((matrix - min_value) / interval_width).clip(0, num_intervals).astype(int) / 2\n",
    "\n",
    "    return transformed_matrix\n",
    "\n",
    "\n",
    "def compute_rmse(predictions, test_matrix):\n",
    "  masked = np.ma.array(test_matrix, mask=np.isnan(test_matrix))\n",
    "  diff = np.ma.subtract(predictions, masked)\n",
    "  squared = np.ma.power(diff, 2)\n",
    "  return np.ma.sqrt(np.ma.mean(squared))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "user_dist = pdist(data, metric='jaccard')\n",
    "user_sim_matrix = squareform(user_dist)\n",
    "\n",
    "movie_dist = pdist(data.T, metric='jaccard')\n",
    "movie_sim_matrix = squareform(movie_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellington/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import scipy.sparse as sps\n",
    "\n",
    "csr_ratings_train = sps.csr_matrix(np.nan_to_num(ratings_train), shape=(610, 4980))\n",
    "csr_ratings_train.eliminate_zeros()\n",
    "\n",
    "nmf = NMF(n_components=10, init='nndsvd', random_state=0, max_iter=200)\n",
    "W = nmf.fit_transform(csr_ratings_train)\n",
    "H = nmf.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellington/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/ot/bregman.py:503: RuntimeWarning: divide by zero encountered in divide\n",
      "  v = b / KtransposeU\n",
      "/Users/ellington/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/ot/bregman.py:511: UserWarning: Warning: numerical errors at iteration 0\n",
      "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are here buddd in 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m Gs \u001b[39m=\u001b[39m ot\u001b[39m.\u001b[39msinkhorn(mu_hat, nu_hat, data, lambd)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m epsilon \u001b[39m=\u001b[39m \u001b[39m.1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m alpha,beta,c \u001b[39m=\u001b[39m cost_learning(data, pi_hat, mu_hat, nu_hat, epsilon, G, D, steps\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;32m/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(c))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m#c_s.append(c)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39m#c = compute_prox(-epsilon*log_k,current_h,c)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(c \u001b[39m-\u001b[39m c_s[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39m<\u001b[39m epsilon:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCs equivalent in iteration \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ellington/dev/masters/ds-projet-2023/assignment1-2023-prestige-worldwide/ek/ot_solver.ipynb#W4sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mreturn\u001b[39;00m epsilon\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlog(u),epsilon\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlog(v),c\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = np.log(1 + np.exp(data))\n",
    "pi_hat = data / data.sum()\n",
    "\n",
    "mu_hat = pi_hat.sum(axis = 1)\n",
    "nu_hat = pi_hat.sum(axis = 0)\n",
    "\n",
    "G = W.T\n",
    "D = H\n",
    "# G = user_sim_matrix\n",
    "# D = movie_sim_matrix\n",
    "\n",
    "lambd = 1e-3\n",
    "Gs = ot.sinkhorn(mu_hat, nu_hat, data, lambd)\n",
    "\n",
    "epsilon = .1\n",
    "\n",
    "alpha,beta,c = cost_learning(data, pi_hat, mu_hat, nu_hat, epsilon, G, D, steps=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.483452151033117\n",
      "3.4740169704546675\n"
     ]
    }
   ],
   "source": [
    "# otm = ot.emd(data.sum(axis=1), data.sum(axis=0), c)\n",
    "otm_scores = transform_to_integers(c)\n",
    "print(compute_rmse(otm_scores, ratings_train))\n",
    "print(compute_rmse(otm_scores, ratings_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 4980)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(otm_scores, return_counts=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
