{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/'\n",
    "data = np.load(data_path + 'ratings_train.npy')\n",
    "data_test = np.nan_to_num(np.load(data_path + 'ratings_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 4980)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import inv\n",
    "A = csc_matrix(data)\n",
    "Ainv = inv(A.T@A)\n",
    "Ainv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan  2. nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "610\n",
      "4980\n"
     ]
    }
   ],
   "source": [
    "A.shape\n",
    "print(data)\n",
    "print(len(data))\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time solver with mask: 4.7507569789886475\n",
      "elapsed time solver without mask: 18.428391456604004\n",
      "Solver no mask\n",
      "RMSE against TRAIN: 0.9284165251272595\n",
      "RMSE against TEST: 1.0298078582682044\n",
      "Solver mask\n",
      "RMSE against TRAIN: 3.5704404164604746\n",
      "RMSE against TEST: 3.562575181679188\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 44 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jules\\OneDrive\\Desktop\\IASD-DS-Assignment1-23\\assignment1-2023-prestige-worldwide\\jm\\LoadingData.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=259'>260</a>\u001b[0m t_1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m solver_als \u001b[39m=\u001b[39m Solve(k\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, mu\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.0005\u001b[39m, beta\u001b[39m=\u001b[39m\u001b[39m0.0005\u001b[39m, train_data\u001b[39m=\u001b[39mdata, n_steps\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m pred \u001b[39m=\u001b[39m solver_als\u001b[39m.\u001b[39;49mmatrix_completion_als()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=262'>263</a>\u001b[0m t_2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=263'>264</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39melapsed time ALS solver: \u001b[39m\u001b[39m{\u001b[39;00mt_2\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mt_1\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\jules\\OneDrive\\Desktop\\IASD-DS-Assignment1-23\\assignment1-2023-prestige-worldwide\\jm\\LoadingData.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(Omega[i, :] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     Vi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mU[indices, :]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     Yi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[i, indices]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#X12sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI[i, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msolve(Vi\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m Vi \u001b[39m+\u001b[39m lambda_reg \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk), Vi\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m Yi)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 44 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "class Solve:\n",
    "\n",
    "    def __init__(self, k, mu, alpha,beta, train_data, descent_method = 'SGD', n_steps = 100, seed = 10):\n",
    "        self.k = k\n",
    "        self.mu = mu\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.data = np.copy(train_data)\n",
    "        self.non_nan = np.argwhere(~np.isnan(train_data))\n",
    "        self.descent = descent_method\n",
    "        self.I = np.random.rand(len(self.data), self.k) #Generating random matrices, maybe a better initialization can be initialized\n",
    "        self.U = np.random.rand(len(self.data[0]), self.k).T\n",
    "        \n",
    "        self.data2 = np.nan_to_num(data, copy=True)\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "    \n",
    "    def compute_sgd(self):\n",
    "        d_I, d_U = 0, 0\n",
    "        for (i, j) in self.non_nan:\n",
    "            eij = data[i][j] - np.dot(self.I[i,:],self.U[:,j])\n",
    "            for k in range(self.k):\n",
    "                d_I += self.I[i][k] + self.alpha * (2 * eij * self.U[k][j] - self.mu * self.I[i][k])\n",
    "                d_U += self.U[k][j] + self.beta * (2 * eij * self.I[i][k] - self.mu * self.U[k][j])\n",
    "\n",
    "        return d_I,d_U\n",
    "    \n",
    "    def train(self, output_loss=False):\n",
    "        loss = []\n",
    "        for _ in range(self.n_steps):\n",
    "            if output_loss:\n",
    "                e = 0\n",
    "                for (i,j) in self.non_nan:\n",
    "                    e = e + pow(self.data[i][j] - np.dot(self.I[i,:],self.U[:,j]), 2)\n",
    "                    for k in range(self.k):\n",
    "                        e = e + (self.mu/2) * (pow(self.I[i][k],2) + pow(self.U[k][j],2))\n",
    "\n",
    "                loss.append(e)\n",
    "\n",
    "            for (i, j) in self.non_nan:\n",
    "                eij = self.data[i][j] - np.dot(self.I[i,:],self.U[:,j])\n",
    "                for k in range(self.k):\n",
    "                    self.I[i, k] = self.I[i, k] + self.alpha * (2 * eij * self.U[k, j] - self.mu * self.I[i, k])\n",
    "                    self.U[k, j] = self.U[k, j] + self.beta * (2 * eij * self.I[i, k] - self.mu * self.U[k, j])\n",
    "                    \n",
    "                    #self.I[i, k] = np.dot(eij, self.U[k, j]) * np.linalg.inv(np.dot(self.U[k, j].T, self.U[k, j]) + self.mu * np.eye(self.k))\n",
    "                    #self.U[k, j] = np.dot(eij.T, self.I[i, k]) * np.linalg.inv(np.dot(self.I[i, k].T, self.I[i, k]) + self.mu * np.eye(self.k))\n",
    "                    \n",
    "                    #self.I[i, k] = np.linalg.solve(np.dot(self.U[k, j].T, self.U[k, j]) + self.mu * np.eye(self.k), np.dot(self.U[k, j].T, eij.T)).T\n",
    "                    #self.U[k, j] = np.linalg.solve(np.dot(self.I[i, k].T, self.I[i, k]) + self.mu * np.eye(self.k), np.dot(self.I[i, k].T, eij))\n",
    "\n",
    "        self.I = np.around(self.I*2, 0)/2\n",
    "        self.U = np.around(self.U*2, 0)/2\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    def als_train(self, output_loss=False):\n",
    "        loss = []\n",
    "        for _ in range(self.n_steps):\n",
    "            if output_loss:\n",
    "                e = 0\n",
    "                for (i, j) in self.non_nan:\n",
    "                    e = e + pow(self.data[i][j] - np.dot(self.I[i, :], self.U[:, j]), 2)\n",
    "                    for k in range(self.k):\n",
    "                        e = e + (self.mu / 2) * (pow(self.I[i][k], 2) + pow(self.U[k][j], 2))\n",
    "\n",
    "                loss.append(e)\n",
    "\n",
    "            for (i, j) in self.non_nan:\n",
    "                eij = self.data[i][j] - np.dot(self.I[i, :], self.U[:, j])\n",
    "                \n",
    "                self.I[i, :] = np.linalg.solve(\n",
    "                    np.dot(self.U[:, j].T, self.U[:, j]) + self.mu * np.eye(self.k),\n",
    "                    np.dot(self.U[:, j].T, eij)\n",
    "                )\n",
    "                self.U[:, j] = np.linalg.solve(\n",
    "                    np.dot(self.I[i, :].T, self.I[i, :]) + self.mu * np.eye(self.k),\n",
    "                    np.dot(self.I[i, :].T, eij)\n",
    "                )\n",
    "\n",
    "        self.I = np.around(self.I * 2, 0) / 2\n",
    "        self.U = np.around(self.U * 2, 0) / 2\n",
    "        return loss\n",
    "    \n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    def matrix_completion_als(self, max_iter=1000, tol=1e-6, lambda_reg=0.1):\n",
    "        m, n = self.data.shape\n",
    "        #U = np.random.rand(m, rank)\n",
    "        #V = np.random.rand(n, rank)\n",
    "        error = 1e10\n",
    "        Omega = (self.data > 0).astype(int)\n",
    "        for it in range(max_iter):\n",
    "            # Update U while fixing V\n",
    "            for i in range(m):\n",
    "                indices = np.where(Omega[i, :] == 1)[0]\n",
    "                Vi = self.U[indices, :]\n",
    "                Yi = self.data[i, indices]\n",
    "                self.I[i, :] = np.linalg.solve(Vi.T @ Vi + lambda_reg * np.eye(self.k), Vi.T @ Yi)\n",
    "        \n",
    "            # Update V while fixing U\n",
    "            for j in range(n):\n",
    "                indices = np.where(Omega[:, j] == 1)[0]\n",
    "                Uj = self.I[indices, :]\n",
    "                Yj = self.data[indices, j]\n",
    "                self.U[j, :] = np.linalg.solve(Uj.T @ Uj + lambda_reg * np.eye(self.k), Uj.T @ Yj)\n",
    "\n",
    "            # Compute the matrix approximation and error\n",
    "            Y_hat = self.I @ self.U.T\n",
    "            diff = Omega * (self.data - Y_hat)\n",
    "            new_error = np.linalg.norm(diff, 'fro')\n",
    "            if abs(new_error - error) < tol:\n",
    "                break\n",
    "            error = new_error\n",
    "    \n",
    "        #return self.I @ self.U.T\n",
    "\n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    \n",
    "    def train_als(self, output_loss = False):\n",
    "        loss = []\n",
    "        for _ in range(self.n_steps):\n",
    "            if output_loss:\n",
    "                e = 0\n",
    "                for (i, j) in self.non_nan:\n",
    "                    e = e + pow(self.data[i][j] - np.dot(self.I[i, :], self.U[:, j]), 2)\n",
    "                    for k in range(self.k):\n",
    "                        e = e + (self.mu / 2) * (pow(self.I[i][k], 2) + pow(self.U[k][j], 2))\n",
    "\n",
    "                loss.append(e)\n",
    "                \n",
    "        for _ in range(self.n_steps):\n",
    "            # Fix U and estimate I\n",
    "            for i in range(self.data.shape[0]):\n",
    "                Ai = np.dot(self.U, self.U.T) + self.mu * np.eye(self.k) + 1e-6 * np.eye(self.k)\n",
    "                det = np.linalg.det(Ai)\n",
    "                if abs(det) < 1e-25:\n",
    "                    Ai += 1e-6 * np.eye(self.k)\n",
    "                print(\"NaN in Ai:\", np.isnan(Ai).sum())\n",
    "                \n",
    "                data_slice = self.data[i, :].T\n",
    "                print(\"NaN in data_slice:\", np.isnan(data_slice).sum())\n",
    "                print(\"Inf in data_slice:\", np.isinf(data_slice).sum())\n",
    "                Vi = np.dot(self.U, data_slice)\n",
    "                \n",
    "                if np.isnan(Vi).sum() > 0:\n",
    "                    print(\"First appearance of NaN in Vi!\")\n",
    "                    print(\"i:\", i)\n",
    "                    print(\"Ui:\", self.U)\n",
    "                    print(\"data_slice:\", data_slice)\n",
    "                    break\n",
    "\n",
    "                #Vi = np.dot(self.U, self.data[i, :].T)\n",
    "                print(\"NaN in Vi:\", np.isnan(Vi).sum())\n",
    "                self.I[i, :] = np.linalg.solve(Ai, Vi)\n",
    "                print(\"NaN in I after update:\", np.isnan(self.I).sum())\n",
    "\n",
    "            # Fix I and estimate U\n",
    "            for j in range(self.data.shape[1]):\n",
    "                Aj = np.dot(self.I.T, self.I) + self.mu * np.eye(self.k) + 1e-6 * np.eye(self.k)\n",
    "                det = np.linalg.det(Aj)\n",
    "                if abs(det) < 1e-25:\n",
    "                    Aj += 1e-6 * np.eye(self.k)\n",
    "                print(\"NaN in Aj:\", np.isnan(Aj).sum())\n",
    "                Vj = np.dot(self.I.T, self.data[:, j])\n",
    "                print(\"NaN in Vj:\", np.isnan(Vj).sum())\n",
    "                self.U[:, j] = np.linalg.solve(Aj, Vj)\n",
    "                print(\"NaN in U after update:\", np.isnan(self.U).sum())\n",
    "                \n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def train_masked(self):\n",
    "        for _ in range(self.n_steps):\n",
    "            masked = np.ma.array(self.data, mask=np.isnan(self.data))\n",
    "            masked_T = np.ma.transpose(masked)\n",
    "            d_U = np.ma.add(np.ma.add(-2*np.ma.dot(masked_T,self.I), 2*self.U.T@self.I.T@self.I) , 2*self.mu*self.U.T)\n",
    "            #d_U = np.ma.add(np.ma.add(-2*masked_T@self.I, 2*self.U@self.I.T@self.I),2*self.mu*self.U)\n",
    "            d_I = np.ma.add(np.ma.add(-2*np.ma.dot(masked,self.U.T) ,2*self.I@self.U@self.U.T), 2*self.mu*self.I)\n",
    "            self.I -= self.alpha*d_I\n",
    "            self.U -= self.beta*d_U.T\n",
    "\n",
    "    def rmse(self, test_matrix):\n",
    "        # diffs = 0\n",
    "        # predictions = self.predict()\n",
    "        # T = len(np.argwhere(~np.isnan(test_matrix)))\n",
    "        # for (i, j) in np.argwhere(~np.isnan(test_matrix)):\n",
    "        #     diff = (test_matrix[i, j] - predictions[i, j])**2\n",
    "        #     diffs += diff\n",
    "        # return np.sqrt(diffs/T)\n",
    "        masked = np.ma.array(test_matrix, mask=np.isnan(test_matrix))\n",
    "        predictions = self.I@self.U\n",
    "        diff = np.ma.subtract(predictions, masked)\n",
    "        squared = np.ma.power(diff, 2)\n",
    "        return np.ma.sqrt(np.ma.mean(squared))\n",
    "    \n",
    "    def rmse_als(self, test_matrix):\n",
    "        predictions = self.I @ self.U\n",
    "        nans = np.isnan(test_matrix)\n",
    "        non_nans = ~nans\n",
    "        num_valid_entries = np.sum(non_nans)\n",
    "    \n",
    "        # Only compute RMSE on non-NaN entries\n",
    "        squared_errors = (test_matrix[non_nans] - predictions[non_nans]) ** 2\n",
    "        mean_squared_error = np.sum(squared_errors) / num_valid_entries\n",
    "    \n",
    "        return np.sqrt(mean_squared_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        return self.I@self.U\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_path = '../datasets/'\n",
    "    data = np.load(data_path + 'ratings_train.npy')\n",
    "    test_data = np.load(data_path + 'ratings_test.npy')\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    t_1 = time.time()\n",
    "    solver_2 = Solve(k=5,mu = 0.0002,alpha = 0.00005,beta = 0.000005,train_data=data, n_steps=50)\n",
    "    pred = solver_2.train_masked()\n",
    "    t_2 = time.time()\n",
    "    print(f'elapsed time solver with mask: {t_2 - t_1}')\n",
    "    t_1 = time.time()\n",
    "    solver = Solve(k=5,mu = 0.02,alpha = 0.0005,beta = 0.0005,train_data=data, n_steps=50)\n",
    "    pred = solver.train()\n",
    "    t_2 = time.time()\n",
    "    print(f'elapsed time solver without mask: {t_2 - t_1}')\n",
    "    rmse = solver.rmse(test_data)\n",
    "    train_rmse = solver.rmse(data)\n",
    "    print(\"Solver no mask\")\n",
    "    print(f\"RMSE against TRAIN: {train_rmse}\")\n",
    "    print(f\"RMSE against TEST: {rmse}\")\n",
    "    rmse = solver_2.rmse(test_data)\n",
    "    train_rmse = solver_2.rmse(data)\n",
    "    print(\"Solver mask\")\n",
    "    print(f\"RMSE against TRAIN: {train_rmse}\")\n",
    "    print(f\"RMSE against TEST: {rmse}\")\n",
    "    \n",
    "    '''\n",
    "    solver_als = Solve(k=5, mu=0.002, alpha=0.00005, beta=0.000005, train_data=data, n_steps=50)\n",
    "    loss = solver_als.als_train(output_loss=True)\n",
    "    t_2 = time.time()\n",
    "    print(f'elapsed time solver with ALS: {t_2 - t_1}')\n",
    "    rmse = solver_als.rmse(test_data)\n",
    "    train_rmse = solver_als.rmse(data)\n",
    "    print(\"Solver with ALS\")\n",
    "    print(f\"RMSE against TRAIN: {train_rmse}\")\n",
    "    print(f\"RMSE against TEST: {rmse}\")\n",
    "    '''\n",
    "    t_1 = time.time()\n",
    "    solver_als = Solve(k=3, mu=0.02, alpha=0.0005, beta=0.0005, train_data=data, n_steps=50)\n",
    "    pred = solver_als.matrix_completion_als()\n",
    "    t_2 = time.time()\n",
    "    print(f'elapsed time ALS solver: {t_2 - t_1}')\n",
    "    rmse = solver_als.rmse(test_data)\n",
    "    train_rmse = solver_als.rmse(data)\n",
    "    predictions = solver_als.predict()\n",
    "    print(\"Number of NaNs in predictions:\", np.isnan(predictions).sum())\n",
    "    print(\"ALS Solver\")\n",
    "    print(f\"RMSE against TRAIN: {train_rmse}\")\n",
    "    print(f\"RMSE against TEST: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = data.shape[0]\n",
    "n = data.shape[1]\n",
    "k = 5\n",
    "mu = .1\n",
    "lam = .1\n",
    "step_I = .00007\n",
    "step_U = .00007\n",
    "I = np.ones((m, k))\n",
    "U = np.ones((n, k))\n",
    "V = 3 * np.random.rand(k,m)\n",
    "W = 3 * np.random.rand(k,n)\n",
    "R = np.nan_to_num(data, copy=True)\n",
    "\n",
    "iters = 100\n",
    "\n",
    "for i in range(iters):\n",
    "  loss = np.linalg.norm((R - I@U.T), ord='fro')**2 + mu*np.linalg.norm(I, ord='fro')**2 + lam*np.linalg.norm(U, ord='fro')**2\n",
    "\n",
    "  #print(f'Loss at iter {i+1}: {loss}')\n",
    "\n",
    "  grad_U = -2*R.T@I + 2*U@I.T@I + 2*mu*U\n",
    "  grad_I = -2*R@U + 2*I@U.T@U + 2*lam*I\n",
    "  \n",
    "  grad_I_als = R@U.dot(U.T@U + lam*np.eye(k))**(-1)\n",
    "  grad_U_als = R.T@I.dot(I.T@I + mu*np.eye(k))**(-1)\n",
    "  \n",
    "  V = grad_I_als\n",
    "  W = grad_U_als\n",
    "\n",
    "  U -= step_U*grad_U\n",
    "  I -= step_I*grad_I\n",
    "\n",
    "\n",
    "rmse = np.sqrt(np.mean((I@U.T-R)**2))\n",
    "print(rmse)\n",
    "\n",
    "rmse_als = np.sqrt(np.mean((V@W.T-R)**2))\n",
    "print(rmse_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/'\n",
    "data = np.load(data_path + 'ratings_train.npy')\n",
    "test_data = np.load(data_path + 'ratings_test.npy')\n",
    "\n",
    "step_I = .00007\n",
    "step_U = .00007\n",
    "\n",
    "mu = .1\n",
    "lam = .1\n",
    "\n",
    "K = 5\n",
    "I = np.random.rand(len(data),K) #Generating random matrices, maybe a better initialization can be initialized\n",
    "U = np.random.rand(len(data[0]),K).T\n",
    "\n",
    "\n",
    "non_nan = np.argwhere(~np.isnan(data))\n",
    "\n",
    "for (i, j) in non_nan:\n",
    "  eij = data[i][j] - np.dot(I[i,:],U[:,j])\n",
    "\n",
    "  for k in range(K):\n",
    "    I[i][k] = I[i][k] + step_I * (2 * eij * U[k][j] - mu * I[i][k])\n",
    "    U[k][j] = U[k][j] + step_U * (2 * eij * I[i][k] - lam * U[k][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix (with missing values set to 0):\n",
      "[[ 4. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan  2. nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "\n",
      "Completed matrix:\n",
      "[[4.62862644 4.09904717 3.6204652  ... 4.41902928 4.13320775 4.68862969]\n",
      " [3.78812708 3.35471264 2.96303503 ... 3.61659009 3.3826701  3.83723452]\n",
      " [1.52249891 1.34830385 1.19088339 ... 1.4535559  1.35954033 1.54223584]\n",
      " ...\n",
      " [3.6135064  3.20007099 2.82644849 ... 3.44987672 3.2267397  3.66035013]\n",
      " [3.53761119 3.13285925 2.76708402 ... 3.37741826 3.15896783 3.58347106]\n",
      " [4.1267091  3.65455616 3.2278705  ... 3.93984017 3.68501245 4.18020575]]\n",
      "0.7510645330526745\n",
      "0.9122087962686874\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialize_with_svd(Y, rank):\n",
    "    # Fill missing values with zeros\n",
    "    Y_filled = np.nan_to_num(Y)\n",
    "\n",
    "    # Perform SVD\n",
    "    U, Sigma, Vt = np.linalg.svd(Y_filled, full_matrices=False)\n",
    "\n",
    "    # Take top `rank` singular vectors/values\n",
    "    U_init = U[:, :rank]\n",
    "    Sigma_init = np.diag(Sigma[:rank])\n",
    "    Vt_init = Vt[:rank, :]\n",
    "\n",
    "    # Initialize U and V\n",
    "    U_initialized = U_init @ np.sqrt(Sigma_init)\n",
    "    V_initialized = (np.sqrt(Sigma_init) @ Vt_init).T\n",
    "\n",
    "    return U_initialized, V_initialized\n",
    "\n",
    "\n",
    "def matrix_completion_als(data, rank, max_iter=100, tol=1e-6, lambda_reg=0.1):\n",
    "    m, n = data.shape\n",
    "    I = np.random.rand(m, rank)\n",
    "    U = np.random.rand(n, rank)\n",
    "    #I, U = initialize_with_svd(data, rank)\n",
    "    error = 1e10\n",
    "    \n",
    "    Omega = (data > 0).astype(int)\n",
    "    #R = np.nan_to_num(data, copy=True)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # Update U while fixing V\n",
    "        for i in range(m):\n",
    "            indices = np.where(Omega[i, :] == 1)[0]\n",
    "            Vi = U[indices, :]\n",
    "            Yi = data[i, indices]\n",
    "            I[i, :] = np.linalg.solve(Vi.T @ Vi + lambda_reg * np.eye(rank), Vi.T @ Yi)\n",
    "        \n",
    "        # Update V while fixing U\n",
    "        for j in range(n):\n",
    "            indices = np.where(Omega[:, j] == 1)[0]\n",
    "            Uj = I[indices, :]\n",
    "            Yj = data[indices, j]\n",
    "            U[j, :] = np.linalg.solve(Uj.T @ Uj + lambda_reg * np.eye(rank), Uj.T @ Yj)\n",
    "\n",
    "        # Compute the matrix approximation and error\n",
    "        Y_hat = I @ U.T\n",
    "        diff = Omega * (data - Y_hat)\n",
    "        new_error = np.linalg.norm(diff, 'fro')\n",
    "        if abs(new_error - error) < tol:\n",
    "            break\n",
    "        error = new_error\n",
    "    \n",
    "    return I @ U.T\n",
    "\n",
    "\n",
    "data_path = '../datasets/'\n",
    "data = np.load(data_path + 'ratings_train.npy')\n",
    "test_data = np.load(data_path + 'ratings_test.npy')\n",
    "\n",
    "\n",
    "# Create the Omega matrix: 1 where Y has an entry, 0 otherwise\n",
    "Omega = (data > 0).astype(int)\n",
    "\n",
    "# Display the generated matrix\n",
    "print(\"Original matrix (with missing values set to 0):\")\n",
    "print(data)\n",
    "\n",
    "\n",
    "# Use the ALS method to complete the matrix\n",
    "completed_matrix = matrix_completion_als(data, rank=1)\n",
    "\n",
    "print(\"\\nCompleted matrix:\")\n",
    "print(completed_matrix)\n",
    "\n",
    "\n",
    "def rmse(completed_matrix, test_matrix):\n",
    "    masked = np.ma.array(test_matrix, mask=np.isnan(test_matrix))\n",
    "    predictions = completed_matrix\n",
    "    diff = np.ma.subtract(predictions, masked)\n",
    "    squared = np.ma.power(diff, 2)\n",
    "    return np.ma.sqrt(np.ma.mean(squared))\n",
    "\n",
    "print(rmse(completed_matrix, data))\n",
    "print(rmse(completed_matrix, test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
