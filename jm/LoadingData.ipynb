{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jules\\OneDrive\\Desktop\\IASD-DS-Assignment1-23\\assignment1-2023-prestige-worldwide\\jm\\LoadingData.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m test_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(data_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mratings_test.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m solver \u001b[39m=\u001b[39m Solve(k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, mu \u001b[39m=\u001b[39m \u001b[39m0.02\u001b[39m, alpha \u001b[39m=\u001b[39m \u001b[39m0.0005\u001b[39m, beta \u001b[39m=\u001b[39m \u001b[39m0.0005\u001b[39m, train_data\u001b[39m=\u001b[39mdata, n_steps\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m pred \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m rmse \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39mrmse(test_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m train_rmse \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39mrmse(data)\n",
      "\u001b[1;32mc:\\Users\\jules\\OneDrive\\Desktop\\IASD-DS-Assignment1-23\\assignment1-2023-prestige-worldwide\\jm\\LoadingData.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         eij \u001b[39m=\u001b[39m data[i][j] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI[i,:], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[:,j])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             \u001b[39m#self.I[i, k] = self.I[i, k] + self.alpha * (2 * eij * self.U[k, j] - self.mu * self.I[i, k])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m             \u001b[39m#self.U[k, j] = self.U[k, j] + self.beta * (2 * eij * self.I[i, k] - self.mu * self.U[k, j])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mI[i, k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(eij, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[k, j]) \u001b[39m*\u001b[39m \u001b[39mpow\u001b[39m(np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[k, j]\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[k, j]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[k, j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(eij\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI[i, k]) \u001b[39m*\u001b[39m \u001b[39mpow\u001b[39m(np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI[i, k]\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI[i, k]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jules/OneDrive/Desktop/IASD-DS-Assignment1-23/assignment1-2023-prestige-worldwide/jm/LoadingData.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "data_path = '../datasets/'\n",
    "data = np.nan_to_num(np.load(data_path + 'ratings_train.npy'))\n",
    "\n",
    "class Solve:\n",
    "\n",
    "    def __init__(self, k, mu, alpha, beta, train_data, descent_method = 'SGD', n_steps = 100):\n",
    "        self.k = k\n",
    "        self.mu = mu\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.data = np.copy(train_data)\n",
    "        self.non_nan = np.argwhere(~np.isnan(data))\n",
    "        self.descent = descent_method\n",
    "        self.I = np.random.rand(len(self.data), self.k) #Generating random matrices, maybe a better initialization can be initialized\n",
    "        self.U = np.random.rand(len(self.data[0]), self.k).T\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "    \n",
    "    def compute_sgd(self):\n",
    "        d_I, d_U = 0, 0\n",
    "        for (i, j) in self.non_nan:\n",
    "            eij = data[i][j] - np.dot(self.I[i,:],self.U[:,j])\n",
    "            for k in range(self.k):\n",
    "                d_I += self.I[i][k] + self.alpha * (2 * eij * self.U[k][j] - self.mu * self.I[i][k])\n",
    "                d_U += self.U[k][j] + self.beta * (2 * eij * self.I[i][k] - self.mu * self.U[k][j])\n",
    "\n",
    "        return d_I,d_U\n",
    "    \n",
    "    def train(self, output_loss=False):\n",
    "        loss = []\n",
    "        for _ in range(self.n_steps):\n",
    "            if output_loss:\n",
    "                e = 0\n",
    "                for (i,j) in self.non_nan:\n",
    "                    e = e + pow(self.data[i][j] - np.dot(self.I[i,:], self.U[:,j]), 2)\n",
    "                    for k in range(self.k):\n",
    "                        e = e + (self.mu/2) * (pow(self.I[i][k],2) + pow(self.U[k][j], 2))\n",
    "\n",
    "                loss.append(e)\n",
    "\n",
    "            for (i, j) in self.non_nan:\n",
    "                eij = data[i][j] - np.dot(self.I[i,:], self.U[:,j])\n",
    "                for k in range(self.k):\n",
    "                    self.I[i, k] = self.I[i, k] + self.alpha * (2 * eij * self.U[k, j] - self.mu * self.I[i, k])\n",
    "                    self.U[k, j] = self.U[k, j] + self.beta * (2 * eij * self.I[i, k] - self.mu * self.U[k, j])\n",
    "                    \n",
    "                    #self.I[i, k] = np.dot(eij, self.U[k, j]) * pow(np.dot(self.U[k, j].T, self.U[k, j]) + self.mu * np.eye(self.k), -1)\n",
    "                    #self.U[k, j] = np.dot(eij.T, self.I[i, k]) * pow(np.dot(self.I[i, k].T, self.I[i, k]) + self.mu * np.eye(self.k), -1)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def rmse(self, test_matrix):\n",
    "        # diffs = 0\n",
    "        # predictions = self.predict()\n",
    "        # T = len(np.argwhere(~np.isnan(test_matrix)))\n",
    "        # for (i, j) in np.argwhere(~np.isnan(test_matrix)):\n",
    "        #     diff = (test_matrix[i, j] - predictions[i, j])**2\n",
    "        #     diffs += diff\n",
    "        # return np.sqrt(diffs/T)\n",
    "        masked = np.ma.array(test_matrix, mask=np.isnan(test_matrix))\n",
    "        predictions = self.I@self.U\n",
    "        diff = np.ma.subtract(predictions, masked)\n",
    "        squared = np.ma.power(diff, 2)\n",
    "        return np.ma.sqrt(np.ma.mean(squared))\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        return self.I@self.U\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_path = '../datasets/'\n",
    "    data = np.load(data_path + 'ratings_train.npy')\n",
    "    test_data = np.load(data_path + 'ratings_test.npy')\n",
    "\n",
    "    solver = Solve(k=5, mu = 0.02, alpha = 0.0005, beta = 0.0005, train_data=data, n_steps=50)\n",
    "    pred = solver.train()\n",
    "    rmse = solver.rmse(test_data)\n",
    "    train_rmse = solver.rmse(data)\n",
    "    print(f\"RMSE against TRAIN: {train_rmse}\")\n",
    "    print(f\"RMSE against TEST: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif self.descent == 'ALS':\n",
    "                self.I = self.data@self.U@(self.U.T@self.U + self.lam*np.eye(self.k))**(-1)\n",
    "                self.U = self.data.T@self.I@(self.I.T@self.I + self.mu*np.eye(self.k))**(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3630064163361999\n",
      "257.69673403705565\n"
     ]
    }
   ],
   "source": [
    "m = data.shape[0]\n",
    "n = data.shape[1]\n",
    "k = 5\n",
    "mu = .1\n",
    "lam = .1\n",
    "step_I = .00007\n",
    "step_U = .00007\n",
    "I = np.ones((m, k))\n",
    "U = np.ones((n, k))\n",
    "V = 3 * np.random.rand(k,m)\n",
    "W = 3 * np.random.rand(k,n)\n",
    "R = np.nan_to_num(data, copy=True)\n",
    "\n",
    "iters = 100\n",
    "\n",
    "for i in range(iters):\n",
    "  loss = np.linalg.norm((R - I@U.T), ord='fro')**2 + mu*np.linalg.norm(I, ord='fro')**2 + lam*np.linalg.norm(U, ord='fro')**2\n",
    "\n",
    "  #print(f'Loss at iter {i+1}: {loss}')\n",
    "\n",
    "  grad_U = -2*R.T@I + 2*U@I.T@I + 2*mu*U\n",
    "  grad_I = -2*R@U + 2*I@U.T@U + 2*lam*I\n",
    "  \n",
    "  grad_I_als = R@U.dot(U.T@U + lam*np.eye(k))**(-1)\n",
    "  grad_U_als = R.T@I.dot(I.T@I + mu*np.eye(k))**(-1)\n",
    "  \n",
    "  V = grad_I_als\n",
    "  W = grad_U_als\n",
    "\n",
    "  U -= step_U*grad_U\n",
    "  I -= step_I*grad_I\n",
    "\n",
    "\n",
    "rmse = np.sqrt(np.mean((I@U.T-R)**2))\n",
    "print(rmse)\n",
    "\n",
    "rmse_als = np.sqrt(np.mean((V@W.T-R)**2))\n",
    "print(rmse_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/'\n",
    "data = np.load(data_path + 'ratings_train.npy')\n",
    "test_data = np.load(data_path + 'ratings_test.npy')\n",
    "\n",
    "step_I = .00007\n",
    "step_U = .00007\n",
    "\n",
    "mu = .1\n",
    "lam = .1\n",
    "\n",
    "K = 5\n",
    "I = np.random.rand(len(data),K) #Generating random matrices, maybe a better initialization can be initialized\n",
    "U = np.random.rand(len(data[0]),K).T\n",
    "\n",
    "\n",
    "non_nan = np.argwhere(~np.isnan(data))\n",
    "\n",
    "for (i, j) in non_nan:\n",
    "  eij = data[i][j] - np.dot(I[i,:],U[:,j])\n",
    "\n",
    "  for k in range(K):\n",
    "    I[i][k] = I[i][k] + step_I * (2 * eij * U[k][j] - mu * I[i][k])\n",
    "    U[k][j] = U[k][j] + step_U * (2 * eij * I[i][k] - lam * U[k][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
